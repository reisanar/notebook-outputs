{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2567bed3-1703-42e8-9cf9-962f0e02dd07",
   "metadata": {},
   "source": [
    "# DATA-780: Classification (Part 1)\n",
    "\n",
    "This classwork (CW) activity explores some of the regression concepts discussed in this unit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff59abff-246e-4941-97c1-ff3f2d63f541",
   "metadata": {},
   "source": [
    "## Classification Problems (Supervised Learning)\n",
    "\n",
    "Classification in machine learning is the process of predicting _discrete class labels_ for input data based on patterns learned from a labeled dataset. It involves training a model using examples where the correct categories are known, allowing the model to learn the relationship between input features and output classes. Once trained, the model can assign new, unseen data points to one of the predefined categories. The primary goal is to develop a model that accurately generalizes to new data, effectively **distinguishing between different classes** based on learned patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6b279e-364d-4e3b-afc4-15222808c8ca",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "Logistic regression is a statistical method used for binary classification tasks. \n",
    "\n",
    "The core idea is to _model the probability that a given input point belongs to a particular class_. This is achieved by applying the logistic function, e.g., the sigmoid function, to a linear combination of input features. The logistic function compresses any real-valued number into a value between 0 and 1, which can be interpreted as a probability.\n",
    "\n",
    "The algorithm estimates the parameters (weights) that best fit the data by _maximizing the likelihood_ of observing the given sample set. This is often done using optimization techniques like gradient descent. Once trained, the model computes the probability of the input belonging to a class, and a threshold (commonly 0.5) is used to make the final classification decision.\n",
    "\n",
    "While it works well for linearly separable data, its performance may decline with more complex patterns unless combined with feature engineering or transformed into non-linear forms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d72464-0600-4e44-98a3-7b54727a46c4",
   "metadata": {},
   "source": [
    "## Example: the Donner Party\n",
    "\n",
    "In 1846, the Donner and Reed families left Springfield, Illinois, for California by covered wagon. In July, the [Donner Party](https://en.wikipedia.org/wiki/Donner_Party), as it became known, reached Fort Bridger, Wyoming. There its leaders decided to attempt a new and untested route to the Sacramento Valley. Having reached its full size of 87 people and 20 wagons, the party was delayed by a difficult crossing of the Wasatch Range and again in the crossing of the desert west of the Great Salt Lake. The group became stranded in the eastern Sierra Nevada mountains when the region was hit by heavy snows in late October. By the time the last survivor was rescued on April 21 1847, 40 of the 87 members had died from famine and exposure to extreme cold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87130d98-d26f-45c0-b6b1-70d5de94b5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d86eed2-e3af-41aa-a216-53afad1dd614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Donner party dataset\n",
    "donner = pd.read_csv(\"https://github.com/reisanar/datasets/raw/master/donner.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5874b0e1-4767-4b42-ae90-d010a47d35f4",
   "metadata": {},
   "source": [
    "We fix the response variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d25f3c-7b93-4bc8-947d-397649409af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change Status to binary (0 for Died, 1 for Survived)\n",
    "# donner['survived'] = (donner['Status'] == 'Survived').astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4764e01a-a39a-46a6-8282-2526de39dfc0",
   "metadata": {},
   "source": [
    "The code below is used to interpret `Sex` as a Categorical Variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1287085a-0d8b-4e6a-95ad-a641d1ea56eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use LabelEncoder()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cfcae8-e70e-48da-ad9b-a7cfe219db40",
   "metadata": {},
   "source": [
    "A quick exploratory data analysis is completed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972f80d1-26b7-4545-8914-0502c5ddaad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.boxplot([donner[donner['Status'] == status]['Age'] for status in ['Died', 'Survived']])\n",
    "# plt.title('Age Distribution by Survival Status')\n",
    "# plt.xlabel('Status')\n",
    "# plt.ylabel('Age')\n",
    "# plt.xticks([1, 2], ['Died', 'Survived'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87aa3dac-f2ba-4fab-8358-d565e31f253e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of survival by sex\n",
    "# use pd.crosstab()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4b7513-71b3-4087-ab00-e4197f2e5474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic logistic regression model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8701fe-0057-402c-a364-ab88e42249f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Basic Logistic Regression Model:\")\n",
    "# print(f\"Intercept: {basic_lr.intercept_[0]:.4f}\")\n",
    "# print(f\"Age Coefficient: {basic_lr.coef_[0][0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e180698-fd06-46dd-be84-b75415fdb867",
   "metadata": {},
   "source": [
    "- The intercept represents the _log odds_ of survival for a party member with an age of 0. From this we can calculate the odds or probability.\n",
    "- The slope indicates how much, for a unit increase in age (being 1 year older), will the _log odds ratio_ change. \n",
    "\n",
    "\n",
    "Probability Calculations are completed below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49181a9-f6c1-4eb2-a6e1-21e69040feb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probability of survival for a newborn (Age = 0)\n",
    "# def predict_survival_prob(model, age):\n",
    "#     return model.predict_proba(np.array([[age]]))[0][1]\n",
    "\n",
    "# print(\"\\nSurvival Probabilities:\")\n",
    "# print(f\"Newborn (Age 0): {predict_survival_prob(basic_lr, 0):.4f}\")\n",
    "# print(f\"25-year-old: {predict_survival_prob(basic_lr, 25):.4f}\")\n",
    "# print(f\"50-year-old: {predict_survival_prob(basic_lr, 50):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dabaa14-0fcc-445a-bc41-5d7457e814d8",
   "metadata": {},
   "source": [
    "Next, we build a second logistic regression model that considers all available attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3013b487-e808-4e0c-8eb6-9e91d483fd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build logistic regression model with both Age and Sex\n",
    "\n",
    "\n",
    "# Full model interpretation\n",
    "# print(\"\\nFull Logistic Regression Model:\")\n",
    "# print(f\"Intercept: {full_lr.intercept_[0]:.4f}\")\n",
    "# print(f\"Age Coefficient: {full_lr.coef_[0][0]:.4f}\")\n",
    "# print(f\"Sex Coefficient: {full_lr.coef_[0][1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080dd46f-37c8-48f9-a3dd-69b0f9f340dc",
   "metadata": {},
   "source": [
    "Below is a visualization of the survival probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbadc20-8650-4279-b858-a9e392fbac17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.scatter(donner['Age'], donner['survived'], alpha=0.7)\n",
    "\n",
    "# # Prediction lines for males and females\n",
    "# age_range = np.linspace(0, 80, 100).reshape(-1, 1)\n",
    "# male_probs = full_lr.predict_proba(np.column_stack([age_range, np.zeros_like(age_range)]))[:, 1]\n",
    "# female_probs = full_lr.predict_proba(np.column_stack([age_range, np.ones_like(age_range)]))[:, 1]\n",
    "\n",
    "# plt.plot(age_range, male_probs, label='Male', color='blue')\n",
    "# plt.plot(age_range, female_probs, label='Female', color='red')\n",
    "\n",
    "# plt.title('Survival Probability by Age and Sex')\n",
    "# plt.xlabel('Age')\n",
    "# plt.ylabel('Probability of Survival')\n",
    "# plt.legend()\n",
    "# plt.grid(True, linestyle='--', alpha=0.7)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390e56a6-c68f-460f-b0d8-916b511ecf6f",
   "metadata": {},
   "source": [
    "### Some notes\n",
    "\n",
    "#### Probability Calculation\n",
    "- The logistic regression model uses the logit transformation:\n",
    "\n",
    "$$\n",
    "\\log \\left( \\frac{p}{1 - p} \\right) = \\beta_0 + \\beta_1 \\text{Age} + \\beta_2 \\text{Sex}\n",
    "$$\n",
    "\n",
    "#### Coefficients Interpretation\n",
    "- Intercept: Base log-odds of survival\n",
    "- Age Coefficient: Negative value indicates decreasing survival probability with age\n",
    "- Sex Coefficient: Positive value suggests higher survival probability for females\n",
    "\n",
    "#### Conclusion\n",
    "Both age and gender appear to have significant effects on survival in the Donner Party, with younger individuals and females having higher probabilities of survival.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24766d1-9c61-4e77-9269-12d54e7958d1",
   "metadata": {},
   "source": [
    "## Example: binary classification on the `iris` dataset\n",
    "\n",
    "We use the `datasets` package to load and return the [iris dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set) into the object `iris`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a94d5b0-af49-42f1-ae00-793dfd382f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import `datasets` from `sklearn`\n",
    "from sklearn import datasets\n",
    "# Import the `numpy` library as `np`\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f553de0-93c0-409c-9724-86b70ea01261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the iris dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99d6c60-2c20-4f94-b010-abc5704dd85d",
   "metadata": {},
   "source": [
    "The \"data\" attribute of the dataset stores the features of each sample flower. Here only the petal length and petal width features are considered. They are extracted and assigned to the feature matrix `X` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc03185-3736-4179-a4b1-88a23eb799d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c0ef7a-ac42-491e-9dc4-9cea2184419a",
   "metadata": {},
   "source": [
    "The \"target\" attribute of the dataset stores the information about the class (label) of each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcab3d7-f954-49c0-8aba-48398bbbf202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433cac57-42a9-478f-8c61-43189b07ec3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the `train_test_split` function from scikit-learn's `cross_validation` module.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into 70% training data and 30% test data. \n",
    "# Used the random_state parameter for reproducibility of the initial shuffling of train/test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0773a0a-ae39-454d-9906-043d84be1284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the `StandardScaler` class from scikit-learn's `preprocessing` module.\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3822aca1-6398-4e3f-8548-7c323490e5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the scaler, which standarizes all the features to have mean=0 and unit variance.\n",
    "\n",
    "\n",
    "# Apply the scaler to the X training data\n",
    "\n",
    "\n",
    "# Apply the SAME scaler to the X test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2961a993-eb84-4619-855e-30182e7470d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the function `accuracy_score` from the `metrics` module.\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c25fa51-12d1-4a45-8168-0b20ce8039fb",
   "metadata": {},
   "source": [
    "We first test with a logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87c0dbf-8907-42ea-ab87-485f61d8f915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get LogisticRegression from sklearn.linear_model\n",
    "\n",
    "\n",
    "# Set LogisticRegressionâ€™s regularization strength parameter (C) to a high value\n",
    "\n",
    "\n",
    "\n",
    "# Fit function to scaled training data and training target to create a model.\n",
    "\n",
    "\n",
    "# Apply the trained logistic regression on the X data to make predicts for the y test data.\n",
    "\n",
    "\n",
    "# View the accuracy of the model, which is: 1 - (observations predicted wrong / total observations).\n",
    "# print('Accuracy: %.2f' % accuracy_score(y_test, y_predLr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
